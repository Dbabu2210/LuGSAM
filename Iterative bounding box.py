# -*- coding: utf-8 -*-
"""scores vs prompts.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YeTyCHTYofxq6pT72jFGYmnPkZKWHAsq
"""

import os
HOME = os.getcwd()
print("HOME:", HOME)

# Commented out IPython magic to ensure Python compatibility.
# %cd {HOME}
!git clone https://github.com/IDEA-Research/GroundingDINO.git
# %cd {HOME}/GroundingDINO
!git checkout -q 57535c5a79791cb76e36fdb64975271354f10251
!pip install -q -e .

# Commented out IPython magic to ensure Python compatibility.
# %cd {HOME}

import sys
!{sys.executable} -m pip install 'git+https://github.com/facebookresearch/segment-anything.git'

!pip uninstall -y supervision
!pip install -q supervision==0.6.0

import supervision as sv
print(sv.__version__)

import os

GROUNDING_DINO_CONFIG_PATH = os.path.join(HOME, "GroundingDINO/groundingdino/config/GroundingDINO_SwinT_OGC.py")
print(GROUNDING_DINO_CONFIG_PATH, "; exist:", os.path.isfile(GROUNDING_DINO_CONFIG_PATH))

# Commented out IPython magic to ensure Python compatibility.
# %cd {HOME}
!mkdir -p {HOME}/weights
# %cd {HOME}/weights

!wget -q https://github.com/IDEA-Research/GroundingDINO/releases/download/v0.1.0-alpha/groundingdino_swint_ogc.pth

import os

GROUNDING_DINO_CHECKPOINT_PATH = os.path.join(HOME, "weights", "groundingdino_swint_ogc.pth")
print(GROUNDING_DINO_CHECKPOINT_PATH, "; exist:", os.path.isfile(GROUNDING_DINO_CHECKPOINT_PATH))

# Commented out IPython magic to ensure Python compatibility.
# %cd {HOME}
!mkdir -p {HOME}/weights
# %cd {HOME}/weights

import os

SAM_CHECKPOINT_PATH = os.path.join(HOME, "weights", "/content/drive/MyDrive/SAM_checkpoints/sam_vit_b_01ec64.pth")
print(SAM_CHECKPOINT_PATH, "; exist:", os.path.isfile(SAM_CHECKPOINT_PATH))

import torch

DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
DEVICE

# Commented out IPython magic to ensure Python compatibility.
# %cd {HOME}/GroundingDINO

from groundingdino.util.inference import Model, predict, annotate, load_image, load_model

grounding_dino_model = Model(model_config_path=GROUNDING_DINO_CONFIG_PATH, model_checkpoint_path=GROUNDING_DINO_CHECKPOINT_PATH, device = DEVICE)

CONFIG_PATH = '/content/GroundingDINO/groundingdino/config/GroundingDINO_SwinT_OGC.py'
WEIGHTS_PATH = '/content/weights/groundingdino_swint_ogc.pth'
model = load_model(CONFIG_PATH, WEIGHTS_PATH)


SAM_ENCODER_VERSION = "vit_b"
from segment_anything import sam_model_registry, SamPredictor
sam = sam_model_registry[SAM_ENCODER_VERSION](checkpoint=SAM_CHECKPOINT_PATH).to(device=DEVICE)
sam_predictor = SamPredictor(sam)

Data_path = '/content/drive/MyDrive/resized_binarized'
BOX_TRESHOLD = 0.25
TEXT_TRESHOLD = 0.25

CLASSES = ['right lobe']
from typing import List

def enhance_class_name(class_names: List[str]) -> List[str]:
    return [
        f"all {class_name}s"
        for class_name
        in class_names
    ]

save_dir = '/content/drive/MyDrive/vit_b/italgorithm/'
os.makedirs(save_dir, exist_ok=True)
print(f"Directory {save_dir} exists: {os.path.exists(save_dir)}")

#perform detections with DINO
import cv2
import supervision as sv
import numpy as np
import matplotlib.pyplot as plt
import os
detections_array = []
# load image
for i in os.listdir(Data_path):
  img = cv2.imread(os.path.join(Data_path,i))
  # detect objects
  detections = grounding_dino_model.predict_with_classes(
      image=img,
      classes=enhance_class_name(class_names=CLASSES[0]),
      box_threshold=BOX_TRESHOLD,
      text_threshold=TEXT_TRESHOLD
  )
  detections_array.append(detections)

img = "/content/drive/MyDrive/Data_full/JPCLN001.png"
image_test = cv2.imread(img)
xy_test = detections_array[0]
xy_test.confidence[0]

def segment(sam_predictor, image, xyxy):
    sam_predictor.set_image(image)
    bb = xyxy  # Assuming xyxy is the bounding box array
    bbox = np.array(bb)
    masks, scores, logits = sam_predictor.predict(box=bbox, multimask_output=False)
    print(scores)
    return scores

score = segment(sam_predictor, image_test, xy_bbox)
score

def bounding_box_area(bbox):
    """
    Calculate the area of the bounding box.

    :param bbox: Bounding box (x_min, y_min, x_max, y_max).
    :return: Area of the bounding box.
    """
    x_min, y_min, x_max, y_max = bbox
    return (x_max - x_min) * (y_max - y_min)

def adjust_bbox(bbox, delta, outward):
    """
    Adjust the bounding box based on the provided delta values and direction.

    :param bbox: The current bounding box.
    :param delta: The delta values for adjustment.
    :param outward: Expand if True, contract if False.
    :return: The adjusted bounding box.
    """
    x_min, y_min, x_max, y_max = bbox
    width = x_max - x_min
    height = y_max - y_min

    if outward:
        return (x_min - delta * width, y_min - delta * height, x_max + delta * width, y_max + delta * height)
    else:
        return (x_min + delta * width, y_min + delta * height, x_max - delta * width, y_max - delta * height)

def calculate_lung_area(image):
    """
    Calculate the lung area from the given chest X-ray image.

    :param image: The chest X-ray image.
    :return: The total lung area.
    """
    if len(image.shape) == 3:
        gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    else:
        gray_image = image

    kernel = np.ones((3, 3), np.uint8)
    cleaned_image = cv2.morphologyEx(gray_image, cv2.MORPH_OPEN, kernel, iterations=2)
    num_labels, labels_im = cv2.connectedComponents(cleaned_image)

    area_counts = np.bincount(labels_im.flatten())[1:]
    lung_labels = area_counts.argsort()[-2:] + 1

    return np.sum(np.isin(labels_im, lung_labels))

def iterative_bbox_refinement(sam_predictor, image, detections, tolerance, translation_factors):
    """
    Iteratively refines the bounding box based on the lung area and given translation factors.

    :param sam_predictor: SAM model predictor function.
    :param image: The image to apply segmentation on.
    :param detection: The initial detection with bounding box and score.
    :param tolerance: Tolerance for the lung area.
    :param translation_factors: List of translation factors for adjustment.
    :return: The refined bounding box and its score.
    """
    bbox_k = detections.xyxy[0]
    score_final = detections.confidence[0]

    for factor in translation_factors:
        outward = calculate_lung_area(image) < tolerance
        bbox_k = adjust_bbox(bbox_k, factor, outward)
        score_k = segment(sam_predictor, image, bbox_k)

        if score_k > score_final:
            score_final = score_k
            bbox_final = bbox_k

    return bbox_final, score_final

#### performing iterative bounding box on the images for various prompts

CLASSES = ['right lobe']
from typing import List

def enhance_class_name(class_names: List[str]) -> List[str]:
    return [
        f"all {class_name}s"
        for class_name
        in class_names
    ]

# load image
tolerance = 2000
translation_factors = [0.01, 0.1, 0.5]
rlobe_itoutput = []
for i in os.listdir(Data_path):
  img = cv2.imread(os.path.join(Data_path,i))
  # detect objects
  detections = grounding_dino_model.predict_with_classes(
      image=img,
      classes=enhance_class_name(class_names=CLASSES[0]),
      box_threshold=BOX_TRESHOLD,
      text_threshold=TEXT_TRESHOLD
  )
  final_bbox, final_score = iterative_bbox_refinement(sam_predictor, image_test, detections, tolerance, translation_factors)
  final = (final_bbox, final_score)
  rlobe_itoutput.append(final)

import pandas as pd
from google.colab import files
rlobe_itoutput_df = pd.DataFrame(rlobe_itoutput)
rlobe_itoutput_df.to_csv('rlobe_itoutput_df.csv')
files.download('rlobe_itoutput_df.csv')

CLASSES = ['Right Lobe', 'right lung', 'Right Lung']
from typing import List

def enhance_class_name(class_names: List[str]) -> List[str]:
    return [
        f"all {class_name}s"
        for class_name
        in class_names
    ]

RLobe_itoutput = []
rlung_itoutput = []
RLung_itoutput = []
for i in range ((len(CLASSES))):
  for i in os.listdir(Data_path):
    img = cv2.imread(os.path.join(Data_path,i))
    # detect objects
    detections = grounding_dino_model.predict_with_classes(
        image=img,
        classes=enhance_class_name(class_names=CLASSES[i]),
        box_threshold=BOX_TRESHOLD,
        text_threshold=TEXT_TRESHOLD
    )
    final_bbox, final_score = iterative_bbox_refinement(sam_predictor, image_test, detections, tolerance, translation_factors)
    final = (final_bbox, final_score)
    RLobe_itoutput.append(final) if CLASSES[i] == 'Right Lobe'
    rlung_itoutput.append(final) if CLASSES[i] == 'right lung'
    RLung_itoutput.append(final) if CLASSES[i] == 'Right Lung'

CLASSES = ['Right Lobe', 'right lung', 'Right Lung']

def enhance_class_name(class_names: List[str]) -> List[str]:
    return [f"all {class_name}s" for class_name in class_names]

# Initialize output lists for each class
RLobe_itoutput = []
rlung_itoutput = []
RLung_itoutput = []

# Iterate over classes and corresponding images
for class_name in CLASSES:
    enhanced_class_names = enhance_class_name([class_name])
    for image_file in os.listdir(Data_path):
        img_path = os.path.join(Data_path, image_file)
        if os.path.isfile(img_path):
            img = cv2.imread(img_path)
            # detect objects for each enhanced class name
            detections = grounding_dino_model.predict_with_classes(
                image=img,
                classes=enhanced_class_names,
                box_threshold=BOX_TRESHOLD,
                text_threshold=TEXT_TRESHOLD
            )
            # Assume the first detection is what we want; adjust as necessary
            if detections:  # Ensure detections are not empty
                final_bbox, final_score = iterative_bbox_refinement(sam_predictor, img, detections, tolerance, translation_factors)
                final = (final_bbox, final_score)

                if class_name == 'Right Lobe':
                    RLobe_itoutput.append(final)
                elif class_name == 'right lung':
                    rlung_itoutput.append(final)
                elif class_name == 'Right Lung':
                    RLung_itoutput.append(final)

RLobe_itoutput_df = pd.DataFrame(RLobe_itoutput)
rlung_itoutput_df = pd.DataFrame(rlung_itoutput)
RLung_itoutput_df = pd.DataFrame(RLung_itoutput)
RLobe_itoutput_df.to_csv('RLobe_itoutput_df.csv')
rlung_itoutput_df.to_csv('rlung_itoutput_df.csv')
RLung_itoutput_df.to_csv('RLung_itoutput_df.csv')
files.download('RLobe_itoutput_df.csv')
files.download('rlung_itoutput_df.csv')
files.download('RLung_itoutput_df.csv')

CLASSES = ['Right . Lobe .', 'RIGHT . LOBE .', 'RIGHT . LUNG .']

def enhance_class_name(class_names: List[str]) -> List[str]:
    return [f"all {class_name}s" for class_name in class_names]

# Initialize output lists for each class
RdotLobedot_itoutput = []
RdotLOBEdot_itoutput = []
RdotLUNGdot_itoutput = []

# Iterate over classes and corresponding images
for class_name in CLASSES:
    enhanced_class_names = enhance_class_name([class_name])
    for image_file in os.listdir(Data_path):
        img_path = os.path.join(Data_path, image_file)
        if os.path.isfile(img_path):
            img = cv2.imread(img_path)
            # detect objects for each enhanced class name
            detections = grounding_dino_model.predict_with_classes(
                image=img,
                classes=enhanced_class_names,
                box_threshold=BOX_TRESHOLD,
                text_threshold=TEXT_TRESHOLD
            )
            # Assume the first detection is what we want; adjust as necessary
            if detections:  # Ensure detections are not empty
                final_bbox, final_score = iterative_bbox_refinement(sam_predictor, img, detections, tolerance, translation_factors)
                final = (final_bbox, final_score)

                if class_name == 'Right . Lobe .':
                    RdotLobedot_itoutput.append(final)
                elif class_name == 'RIGHT . LOBE .':
                    RdotLOBEdot_itoutput.append(final)
                elif class_name == 'RIGHT . LUNG .':
                    RdotLUNGdot_itoutput.append(final)

RdotLobedot_itoutput_df = pd.DataFrame(RdotLobedot_itoutput)
RdotLOBEdot_itoutput_df = pd.DataFrame(RdotLOBEdot_itoutput)
RdotLUNGdot_itoutput_df = pd.DataFrame(RdotLUNGdot_itoutput)
RdotLobedot_itoutput_df.to_csv('RdotLobedot_itoutput_df.csv')
RdotLOBEdot_itoutput_df.to_csv('RdotLOBEdot_itoutput_df.csv')
RdotLUNGdot_itoutput_df.to_csv('RdotLUNGdot_itoutput_df.csv')
files.download('RdotLobedot_itoutput_df.csv')
files.download('RdotLOBEdot_itoutput_df.csv')
files.download('RdotLOBEdot_itoutput_df.csv')

CLASSES = ['left lobe', 'Left Lobe']
from typing import List
def enhance_class_name(class_names: List[str]) -> List[str]:
    return [f"all {class_name}s" for class_name in class_names]

# Initialize output lists for each class
llobe_itoutput = []
LLobe_itoutput = []
llung_itoutput = []
LLung_itoutput = []
LdotLobedot_itoutput = []
LdotLOBEdot_itoutput = []
LdotLUNGdot_itoutput = []

# Iterate over classes and corresponding images
for class_name in CLASSES:
    enhanced_class_names = enhance_class_name([class_name])
    for image_file in os.listdir(Data_path):
        img_path = os.path.join(Data_path, image_file)
        if os.path.isfile(img_path):
            img = cv2.imread(img_path)
            # detect objects for each enhanced class name
            detections = grounding_dino_model.predict_with_classes(
                image=img,
                classes=enhanced_class_names,
                box_threshold=BOX_TRESHOLD,
                text_threshold=TEXT_TRESHOLD
            )
            # Assume the first detection is what we want; adjust as necessary
            if detections:  # Ensure detections are not empty
                final_bbox, final_score = iterative_bbox_refinement(sam_predictor, img, detections, tolerance, translation_factors)
                final = (final_bbox, final_score)

                if class_name == 'left lobe':
                    llobe_itoutput.append(final)
                elif class_name == 'Left Lobe':
                    LLobe_itoutput.append(final)
                elif class_name == 'left lung':
                    llung_itoutput.append(final)
                elif class_name == 'Left Lung':
                    LLung_itoutput.append(final)
                elif class_name == 'Left . Lobe .':
                    LdotLobedot_itoutput.append(final)
                elif class_name == 'LEFT . LOBE .':
                    LdotLOBEdot_itoutput.append(final)
                elif class_name == 'LEFT . LUNG .':
                    LdotLUNGdot_itoutput.append(final)

llobe_itoutput_df = pd.DataFrame(llobe_itoutput)
LLobe_itoutput_df = pd.DataFrame(LLobe_itoutput)
llung_itoutput_df = pd.DataFrame(llung_itoutput)
LLung_itoutput_df = pd.DataFrame(LLung_itoutput)
LdotLobedot_itoutput_df = pd.DataFrame(LdotLobedot_itoutput)
LdotLOBEdot_itoutput_df = pd.DataFrame(LdotLOBEdot_itoutput)
LdotLUNGdot_itoutput_df = pd.DataFrame(LdotLUNGdot_itoutput)

llobe_itoutput_df.to_csv('llobe_itoutput_df.csv')
LLobe_itoutput_df.to_csv('LLobe_itoutput_df.csv')
llung_itoutput_df.to_csv('llung_itoutput_df.csv')
LLung_itoutput_df.to_csv('LLung_itoutput_df.csv')
LdotLobedot_itoutput_df.to_csv('LdotLobedot_itoutput_df.csv')
LdotLOBEdot_itoutput_df.to_csv('LdotLOBEdot_itoutput_df.csv')
LdotLUNGdot_itoutput_df.to_csv('LdotLUNGdot_itoutput_df.csv')


files.download('llobe_itoutput_df.csv')
files.download('LLobe_itoutput_df.csv')
files.download('llung_itoutput_df.csv')
files.download('LLung_itoutput_df.csv')
files.download('LdotLobedot_itoutput_df.csv')
files.download('LdotLOBEdot_itoutput_df.csv')
files.download('LdotLUNGdot_itoutput_df.csv')





##evaluation code

import numpy as np

def dice_coefficient(predicted_mask, ground_truth_mask):
    predicted_mask = np.asarray(predicted_mask).astype(np.bool)
    ground_truth_mask = np.asarray(ground_truth_mask).astype(np.bool)

    intersection = np.logical_and(predicted_mask, ground_truth_mask)

    return 2. * intersection.sum() / (predicted_mask.sum() + ground_truth_mask.sum())

# Example usage:
# dice = dice_coefficient(generated_mask, ground_truth_mask)
# print("Dice Coefficient:", dice)

from google.colab import files
files.download("/content/my_masks_vit_b")

